local: &local
  service: 'Disk'
  root: <%= Rails.root.join("storage") %>

amazon: &amazon
  service: 'S3'
  access_key_id: <%= ENV['AWS_S3_KEY_ID'] || 'not-used-access_key_id' %>
  secret_access_key: <%= ENV['AWS_S3_SECRET_KEY'] || 'not-used-secret_access_key' %>
  region: <%= S3QueryService.pre_curation_config.fetch(:region) %>
  bucket: <%= S3QueryService.pre_curation_config.fetch(:bucket) %>

development: &development
# AWS is the default as the will not really work without AWS
#  You can go back to local if needed for some reason, just be aware the uploaded
#  files will not display in the edit or the show pages
#  <<: *local
   <<: *amazon


amazon_pre_curation:
  <% if Rails.env.development? %>
    <<: *development
  <% else %>
    <<: *amazon
    region: <%= S3QueryService.pre_curation_config.fetch(:region) %>
    bucket: <%= S3QueryService.pre_curation_config.fetch(:bucket) %>
  <% end %>

test: &test
  <<: *amazon
  access_key_id: 'not-used-access_key_id'
  secret_access_key: 'not-used-secret_access_key'

staging: *amazon

production: *amazon

# Use rails credentials:edit to set the AWS secrets (as aws:access_key_id|secret_access_key)
# amazon:
#   service: S3
#   access_key_id: <%= Rails.application.credentials.dig(:aws, :access_key_id) %>
#   secret_access_key: <%= Rails.application.credentials.dig(:aws, :secret_access_key) %>
#   region: us-east-1
#   bucket: your_own_bucket

# Remember not to checkin your GCS keyfile to a repository
# google:
#   service: GCS
#   project: your_project
#   credentials: <%= Rails.root.join("path/to/gcs.keyfile") %>
#   bucket: your_own_bucket

# Use rails credentials:edit to set the Azure Storage secret (as azure_storage:storage_access_key)
# microsoft:
#   service: AzureStorage
#   storage_account_name: your_account_name
#   storage_access_key: <%= Rails.application.credentials.dig(:azure_storage, :storage_access_key) %>
#   container: your_container_name

# mirror:
#   service: Mirror
#   primary: local
#   mirrors: [ amazon, google, microsoft ]
